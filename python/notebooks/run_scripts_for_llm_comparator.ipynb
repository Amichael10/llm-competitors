{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kunEkAgFB9Yt"
      },
      "outputs": [],
      "source": [
        "! pip install /content/llm_comparator-0.1-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZlVpN83nJBv"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from google.colab import auth\n",
        "\n",
        "from llm_comparator import comparison\n",
        "from llm_comparator import model_helper\n",
        "from llm_comparator import llm_judge_runner\n",
        "from llm_comparator import rationale_bullet_generator\n",
        "from llm_comparator import rationale_cluster_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ygUJPVxDMB7"
      },
      "outputs": [],
      "source": [
        "#@title Setup for using Vertex AI.\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = 'pair-experimental'  #@param {type: \"string\"}\n",
        "REGION = 'us-central1'  #@param {type: \"string\"}\n",
        "\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBGp4LiVCO00"
      },
      "outputs": [],
      "source": [
        "llm_judge_inputs = [\n",
        "    {'prompt': 'how are you?', 'response_a': 'good', 'response_b': 'bad'},\n",
        "    {'prompt': 'hello?', 'response_a': 'hello', 'response_b': 'hi'},\n",
        "    {'prompt': 'what is the capital of korea?', 'response_a': 'Seoul', 'response_b': 'Vancouver'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy6GxkgJCD-M"
      },
      "outputs": [],
      "source": [
        "#@title Initialize models used in the LLM Comparator evaluation.\n",
        "generator = model_helper.VertexGenerationModelHelper()\n",
        "embedder = model_helper.VertexEmbeddingModelHelper()\n",
        "judge = llm_judge_runner.LLMJudgeRunner(generator)\n",
        "bulletizer = rationale_bullet_generator.RationaleBulletGenerator(generator)\n",
        "clusterer = rationale_cluster_generator.RationaleClusterGenerator(\n",
        "    generator, embedder\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUU3V63vVbvS"
      },
      "outputs": [],
      "source": [
        "#@title Run the LLM Comparator evauation.\n",
        "comparison_result = comparison.run(\n",
        "    llm_judge_inputs,\n",
        "    judge,\n",
        "    bulletizer,\n",
        "    clusterer,\n",
        ")"
      ]
    },
    {
      "metadata": {
        "id": "hViMkxUGhnTA"
      },
      "cell_type": "code",
      "source": [
        "file_path = 'json_for_llm_comparator.json' # @param {type: \"string\"}\n",
        "comparison.write(comparison_result, file_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "3_kgtTlOtI8s"
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/PAIR-code/llm-comparator"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiKOappAwtkv"
      },
      "outputs": [],
      "source": [
        "#@title For displaying LLM Comparator.\n",
        "import IPython\n",
        "\n",
        "# TODO: Move to the pip package.\n",
        "def show_llm_comparator(json_path, height=800, port=4321):\n",
        "  IPython.get_ipython().system_raw(f'python3 -m http.server {port} \u0026')\n",
        "  IPython.display.display(IPython.display.Javascript(\"\"\"\n",
        "  (async ()=\u003e{\n",
        "    fm = document.createElement('iframe')\n",
        "    fm.src = await google.colab.kernel.proxyPort(%s)\n",
        "    results_path = fm.src + '%s'\n",
        "    fm.src += 'llm-comparator/docs/'\n",
        "    fm.src += '?results_path=' + results_path\n",
        "    fm.width = '100%%'\n",
        "    fm.height = '%d'\n",
        "    fm.frameBorder = 0\n",
        "    document.body.append(fm)\n",
        "  })();\n",
        "  \"\"\" % (port, json_path, height) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-o0bDW4wvnR"
      },
      "outputs": [],
      "source": [
        "show_llm_comparator(file_path, port=7676)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:comparator12-2::citc",
          "timestamp": 1718335330333
        },
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:fig-export-comparator12-2-3818-change-2::citc",
          "timestamp": 1718334507750
        },
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:fig-export-comparator12-2-3818-change-2::citc",
          "timestamp": 1718215678229
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
