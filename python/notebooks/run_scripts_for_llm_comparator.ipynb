{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kunEkAgFB9Yt"
      },
      "outputs": [],
      "source": [
        "# !pip install llm-comparator"
      ]
    },
    {
      "metadata": {
        "id": "QZlVpN83nJBv"
      },
      "cell_type": "code",
      "source": [
        "# Run this if using a google3 Colab Kernel, such as with\n",
        "# blaze run //third_party/javascript/llm_comparator/python/src/llm_comparator:kernel\n",
        "# Otherwise, import modules using the following cell.\n",
        "from llm_comparator import model_helper\n",
        "from llm_comparator import llm_judge_runner\n",
        "from llm_comparator import rationale_bullet_generator\n",
        "from llm_comparator import rationale_cluster_generator\n",
        "import vertexai"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82SyO0LFCLPy"
      },
      "outputs": [],
      "source": [
        "from llm_comparator import model_helper\n",
        "from llm_comparator import llm_judge_runner\n",
        "from llm_comparator import rationale_bullet_generator\n",
        "from llm_comparator import rationale_cluster_generator\n",
        "import vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ygUJPVxDMB7"
      },
      "outputs": [],
      "source": [
        "#@title Setup for using Vertex AI.\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = 'pair-experimental'  #@param {type: \"string\"}\n",
        "REGION = 'us-central1'  #@param {type: \"string\"}\n",
        "\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "generator = model_helper.VertexGenerationModelHelper()\n",
        "embedder = model_helper.VertexEmbeddingModelHelper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBGp4LiVCO00"
      },
      "outputs": [],
      "source": [
        "llm_judge_inputs = [\n",
        "    {'prompt': 'how are you?', 'response_a': 'good', 'response_b': 'bad'},\n",
        "    {'prompt': 'hello?', 'response_a': 'hello', 'response_b': 'hi'},\n",
        "    {'prompt': 'what is the capital of korea?', 'response_a': 'Seoul', 'response_b': 'Vancouver'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy6GxkgJCD-M"
      },
      "outputs": [],
      "source": [
        "# Run LLM judge.\n",
        "judge = llm_judge_runner.LLMJudgeRunner(generator)\n",
        "judge_outputs = judge.run(llm_judge_inputs, 4)\n",
        "\n",
        "# Generate bulleted summary of rationales.\n",
        "bullet_generator = rationale_bullet_generator.RationaleBulletGenerator(\n",
        "    generator)\n",
        "bullet_generator_outputs = bullet_generator.run(judge_outputs)\n",
        "\n",
        "# Cluster the bulleted summary of rationales.\n",
        "clusterer = rationale_cluster_generator.RationaleClusterGenerator(\n",
        "    generator, embedder)\n",
        "clusters, rationales_with_similarities = clusterer.run(\n",
        "    bullet_generator_outputs, num_clusters=5\n",
        ")\n",
        "\n",
        "# TODO: Create a wrapper class that includes both LLM judge and rationale summary (not implemented yet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X33Th6Kiw_Ja"
      },
      "outputs": [],
      "source": [
        "#@title Prepare JSON for LLM Comparator\n",
        "# TODO: Move to the pip package.\n",
        "import json\n",
        "\n",
        "llm_comparator_data = {\n",
        "    'metadata': {'custom_fields_schema': []},\n",
        "    'models': [{'name': 'A'}, { 'name': 'B'}],\n",
        "    'examples': [{\n",
        "        'input_text': input['prompt'],\n",
        "        'tags': [],\n",
        "        'output_text_a': input['response_a'],\n",
        "        'output_text_b': input['response_b'],\n",
        "        'score': judge_output['score'],\n",
        "        'individual_rater_scores': judge_output['individual_rater_scores'],\n",
        "        'rationale_list': rationales_with_similarities_for_ex,\n",
        "    } for input, judge_output, rationales_with_similarities_for_ex in zip(\n",
        "        llm_judge_inputs, judge_outputs, rationales_with_similarities)],\n",
        "    'rationale_clusters': clusters,\n",
        "}\n",
        "\n",
        "with open('json_for_llm_comparator.json', 'w') as f:\n",
        "  json.dump(llm_comparator_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1mE-MKAwsA6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PAIR-code/llm-comparator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiKOappAwtkv"
      },
      "outputs": [],
      "source": [
        "#@title For displaying LLM Comparator.\n",
        "from IPython.display import Javascript\n",
        "\n",
        "# TODO: Move to the pip package.\n",
        "def show_llm_comparator(json_path, height=800, port=8888):\n",
        "  get_ipython().system_raw(f'python3 -m http.server {port} \u0026')\n",
        "  display(Javascript(\"\"\"\n",
        "  (async ()=\u003e{\n",
        "    fm = document.createElement('iframe')\n",
        "    fm.src = await google.colab.kernel.proxyPort(%s)\n",
        "    results_path = fm.src + '%s'\n",
        "    fm.src += 'llm-comparator/docs/'\n",
        "    fm.src += '?results_path=' + results_path\n",
        "    fm.width = '100%%'\n",
        "    fm.height = '%d'\n",
        "    fm.frameBorder = 0\n",
        "    document.body.append(fm)\n",
        "  })();\n",
        "  \"\"\" % (port, json_path, height) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-o0bDW4wvnR"
      },
      "outputs": [],
      "source": [
        "show_llm_comparator('json_for_llm_comparator.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:comparator12-2::citc",
          "timestamp": 1718335330333
        },
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:fig-export-comparator12-2-3818-change-2::citc",
          "timestamp": 1718334507750
        },
        {
          "file_id": "/piper/depot/google3/third_party/javascript/llm_comparator/python/notebooks/run_scripts_for_llm_comparator.ipynb?workspaceId=kahng:fig-export-comparator12-2-3818-change-2::citc",
          "timestamp": 1718215678229
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
